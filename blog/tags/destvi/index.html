<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="scvi-tools Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="scvi-tools Blog Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><title data-react-helmet="true">One post tagged with &quot;destvi&quot; | scvi-tools</title><meta data-react-helmet="true" property="og:title" content="One post tagged with &quot;destvi&quot; | scvi-tools"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://scvi-tools.org/blog/tags/destvi"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="blog_tags_posts"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://scvi-tools.org/blog/tags/destvi"><link data-react-helmet="true" rel="alternate" href="https://scvi-tools.org/blog/tags/destvi" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://scvi-tools.org/blog/tags/destvi" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.34d598f1.css">
<link rel="preload" href="/assets/js/runtime~main.a95fbbf9.js" as="script">
<link rel="preload" href="/assets/js/main.5868d4e3.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/logo.svg" alt="scvi-tools Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/img/logo.svg" alt="scvi-tools Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">scvi-tools</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/get_started">Get Started</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link">Docs</a><ul class="dropdown__menu"><li><a href="https://docs.scvi-tools.org" target="_self" rel="noopener noreferrer" class="dropdown__link"><span>Full documentation<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li><a href="https://docs.scvi-tools.org/en/stable/tutorials/index.html" target="_self" rel="noopener noreferrer" class="dropdown__link"><span>Tutorials<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li><a href="https://docs.scvi-tools.org/en/stable/user_guide/index.html" target="_self" rel="noopener noreferrer" class="dropdown__link"><span>User guide<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li><a href="https://docs.scvi-tools.org/en/stable/api/index.html" target="_self" rel="noopener noreferrer" class="dropdown__link"><span>API reference<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link">About</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/team">Team</a></li><li><a class="dropdown__link" href="/press">Press</a></li><li><a class="dropdown__link" href="/ecosystem">Ecosystem</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a href="https://discourse.scvi-tools.org/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Discussion<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://github.com/YosefLab/scvi-tools" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-tags-post-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_2ahu thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_2hhb margin-bottom--md">Recent posts</div><ul class="sidebarItemList_2xAf"><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/v13">scvi-tools 1.3 release</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/destvi-batchsize">Mini-batch size in destVI</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/v090">scvi-tools 0.9.0 release</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/autotune">Hyperparameter search for scVI</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/zero-inflation">Should we zero-inflate scVI?</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>One post tagged with &quot;destvi&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/blog/destvi-batchsize">Mini-batch size in destVI</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2022-05-29T00:00:00.000Z" itemprop="datePublished">May 29, 2022</time> Â· 15 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a itemprop="url"><span itemprop="name">Can Ergen, Romain Lopez, Nir Yosef</span></a></div></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>The task of deconvolution of spot-based spatial transcriptomics (ST) data consists in finding the cellular composition in spots of ST assays. Indeed, by design each spot consists of several individual cells. Our lab developed destVI as a tool to study cell type composition of spots (1). In the case where one expects within cell type variation (i.e., activation states), DestVI was designed to infer the activation state of individual cell types in each spot and therefore gives additional resolution of cell composition over competing algorithms. In our own benchmarking of destVI, we found comparable performance in prediction of cell type proportions to other state of the art algorithms like Cell2Location (2). A recent benchmarking study compared the performance of several gene imputation as well as deconvolution methods. Given the ever increasing number of deconvolution methods, the effort to benchmark those tools on a variety of simulated data is timely (3). In two of the benchmarking cases, DestVI had the worst performance. Along with the recent acceptance of the manuscript, we published several fixes to the codebase in scvi-tools v0.16.0, repeated those experiments and analyzed the reasons for failure of spot deconvolution in the given experiments. Briefly, we show that the poor performance was due to the mini-batch size used during optimization, and resolving this help recovering competitive accuracy. Additionally, we provide the user with a heuristic for future use.</p><p>More specifically, variational autoencoders are a specific type of neural networks (NN) that, like most NN, are trained by iteratively presenting the network mini-batches of data, that is a small fraction of the whole dataset. The mini-batch size refers to number of distinct samples used for updating the parameters of the neural networks during one training step.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="methodology"></a>Methodology<a class="hash-link" href="#methodology" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="models"></a>Models<a class="hash-link" href="#models" title="Direct link to heading">#</a></h3><p>The DestVI model (1) uses a first training phase on a reference single cell dataset to learn a cell-type specific latent space. Then, it learns a second model using as input the spot data, and encoding them in the reference latent space. Finally, the model learns cell-type proportions for each spot. In this blog post, we only address the cell-type proportion estimate as was done in the original benchmarking study (3). We haven&#x27;t checked the activation state of those cells as the simulation was designed in a way where the mean activation state of each cell-type in each spot is not known and ground-truth therefore is missing. For all experiments here, we kept the parameters for the CondSCVI model on which the single-cell data is learned constant and highlight every parameter we changed in the respective run. The only two parameters that we highlight here are the amortization scheme, where destVI allows a neural network for amortization of cell-type proportions and activation state or models them as free parameters, and the mini-batch size used for training.</p><p>The selection of genes for destVI used in the original benchmarking study is a point we wanted to mention here. The authors first took the intersection of the genes in spatial assay and single cell assay (882 genes overlapping for STARmap dataset) and then took the 2000 highly variable genes. This second step was without effect (2000 is higher than 882). Nevertheless, in case a FISH based experiments was designed specifically for an organ and all genes were carefully selected, we generally would recommend against additional filtering for over-dispersed genes in a single cell reference but train the model directly on the overlap of spatial and single cell genes skipping the step of highly variable genes.</p><p>We compare destVI throughout this blog post with the benchmark version of Cell2Location. Our purpose is not to prove that we outperform other existing methods but to analyze why destVI showed poor performance in the benchmarking study. Cell2Location showed overall good performance in the benchmarking study and is implemented using the scvi-tools framework but relies on a marker gene related approach instead of an unbiased deconvolution approach.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="hyperparameter-selection"></a>Hyperparameter selection<a class="hash-link" href="#hyperparameter-selection" title="Direct link to heading">#</a></h3><p>Most experiments before the destVI publication, as well as the benchmarking study were performed using cell-type activation state amortization only (called latent amortization hereafter) and treat the cell-type proportions as a free parameter. However, in the recent version of the code we generally recommend to use the amortized version of both (called both amortization hereafter). In this blog post, we checked performance in all experiments here for both amortization schemes. The size of the training mini-batch size varied as {4, 8, 16, 32, 64, 128, 256, 512, 1024}. For comparison with the benchmarking study we left out batch sizes 256 or higher because the number of spots was 189. For our comparison, in a large scale dataset we left out batch_sizes 16 and lower because the training time drastically increases when using small batch sizes on large datasets.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="results"></a>Results<a class="hash-link" href="#results" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="datasets"></a>Datasets<a class="hash-link" href="#datasets" title="Direct link to heading">#</a></h3><p>We reused the STARmap dataset from the original publication (mouse brain cortex). The single-cell reference contains 14,249 cells by 34,041 genes. It contains data from several mouse lines, both sexes and from various time points that were sorted by flow cytometry and sequentially sequenced. The STARmap dataset contains 1,523 cells by 981 genes. The simulation is to sum all counts over a window size of 750 pixels. This gives a pseudo-spot count matrix with 189 spots and 1-17 cells per spot. For further reference, we refer to the original publication (3). We subset this dataset to 57 spots to see how destVI performs in the case of even lower number of spots by subsetting this data to the first three column as diversity of cell-types is mainly along the cortical axis and subsetting to columns keeps the complexity of the dataset similar.</p><p>For a regime with more spots, we decided to keep the organ of interest (mouse brain) and use a dataset with a much higher number of cell captured. We reproduced for this matter the analysis provided by Vizgen using MERFISH technology, which provides a walk-through tutorial on Google Colab.</p><img alt="MERFISH_data" width="100%" src="/img/blog-post-destvi-batchsize/vizgen_colab.png"><p>Figure 1: Overview of MERFISH brain dataset from (<a href="https://colab.research.google.com/drive/1OxJRO19cPsDW0JGAh4tLJjgOl7EMxQbP?usp=sharing&amp;__hstc=30510752.37206d737856c71bb0a5d1c8f6764b63.1652985789816.1653807477271.1653882474080.8&amp;__hssc=30510752.1.1653882474080&amp;__hsfp=455698764&amp;hsCtaTracking=070f4af1-2595-44c8-9779-4da89d538482%7Cf4313de5-25c4-4677-9fd6-82cf71d4fdc4" target="_blank" rel="noopener noreferrer">https://colab.research.google.com/drive/1OxJRO19cPsDW0JGAh4tLJjgOl7EMxQbP?usp=sharing&amp;__hstc=30510752.37206d737856c71bb0a5d1c8f6764b63.1652985789816.1653807477271.1653882474080.8&amp;__hssc=30510752.1.1653882474080&amp;__hsfp=455698764&amp;hsCtaTracking=070f4af1-2595-44c8-9779-4da89d538482%7Cf4313de5-25c4-4677-9fd6-82cf71d4fdc4</a>).</p><p>This analysis yields a single-cell reference dataset with 160,796 cells by 27,998 genes and a spatial dataset with 83,546 cells by 483 genes. The simulation here is again to sum all counts of cells with a center over a window of 40 Âµm. We choose the size of this window to have an equal number of cells per pseudo-spot compared to the STARmap dataset. This gives a pseudo-spot count matrix with 27395 spots and 1-16 cells per spot.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="results-on-starmap-dataset"></a>Results on STARmap dataset<a class="hash-link" href="#results-on-starmap-dataset" title="Direct link to heading">#</a></h3><p>First, we verified that by using the updated version of the code in scvi-tools v0.16.0, we get similar results to the benchmarking study. In agreement with the original benchmarking study, the layer structure of neurons in different cortical layers wasn&#x27;t visible.</p><p>Then, we ran different amortization variants of DestVI. Modeling cell-type proportions as a free parameter leads to no visible structure at all (as was run by the study). When using amortized cell-type proportions, which uses a neural network to estimate cell-type proportions, destVI predicted astrocytes correctly, while it wasn&#x27;t capable of differentiating different excitatory neurons but were classifying all neurons as a single mixture.</p><p>By changing the batch-size, we noticed that decreasing the training mini-batch size drastically improves the performance of both algorithms.  Notably, the model with a mini-batch size of 32 and both parameters amortized performs badly. We see good deconvolution of the different neuronal layers with a batch size of 8, 12 and 16. Additionally, for these batch size there was no qualitative difference between both amortization and latent amortization.</p><p>When comparing the results of destVI with Cell2Location it becomes clear that Cell2Location outperforms destVI for cell-types like Pvalp or Smc cells while both algorithms fail on microglia. The reason for better performance of Cell2Location is most likely low number of those cell-types in the spatial dataset and therefore low percentage in the respective spot. The bad performance for microglia might be based on the selection of FISH probes giving a low coverage of myeloid cell heterogeneity.</p><img alt="STARmap" width="100%" src="/img/blog-post-destvi-batchsize/STARmap.png"><p>Figure 2: Results on benchmarking dataset. Left-to-right ground truth, Cell2Location, DestVI with both amortization and batch-size 8, 16, 48, 128 and DestVI with latent amortization with same batch size. Increase in matching proportions for destVI with decreasing mini-batch size. Cell2Location outperforms destVI for Oligodendrocytes. Quantitative measurues (PCC=Pearson Correlation Coefficient, SSIM=Structural Similarity, RMSE=Root Mean Squared Error, JSD=Jensen-Shannon-Divergence) show on par performance for destVI with a mini-batch size below 16.</p><table><thead><tr><th>cell-type</th><th>freq_sc</th><th>freq_spatial</th></tr></thead><tbody><tr><td>ExcitatoryL6</td><td>3190</td><td>287</td></tr><tr><td>ExcitatoryL5</td><td>1786</td><td>94</td></tr><tr><td>Sst</td><td>1741</td><td>42</td></tr><tr><td>Vip</td><td>1728</td><td>15</td></tr><tr><td>ExcitatoryL4</td><td>1401</td><td>198</td></tr><tr><td>Pvalb</td><td>1337</td><td>42</td></tr><tr><td>ExcitatoryL2and3</td><td>982</td><td>258</td></tr><tr><td>Astro</td><td>368</td><td>141</td></tr><tr><td>Endo</td><td>94</td><td>150</td></tr><tr><td>Olig</td><td>91</td><td>200</td></tr><tr><td>Smc</td><td>55</td><td>13</td></tr><tr><td>Micro</td><td>51</td><td>23</td></tr></tbody></table><p>When checking quantitative results, we find on par performance of destVI and Cell2Location in Pearson Correlation Coefficient based on spots while when checking for correlation across cell-types Cell2Location outperforms destVI. The reason for this improved performance are as described above lowly abundant cell-types.</p><p>As demonstrated here, by reducing the size of the training mini-batch destVI yields overall similar performance to Cell2Location for cell-type deconvolution. We asked next whether this is also the case when even further reducing the number of spots. For this study, as described above we subset the number of pseudo-spots and retrained Cell2Location and destVI. Overall, we find better agreement with both amortization for different sizes of training batch size. Oligodendrocytes and Astrocytes are correctly predicted in all version with both amortization. Only the models with a batch size of 4 differentiate between the different layers of excitatory neurons. Of note, latent amortization outperforms both amortization here for a mini-batch size of 4. It might be an effect of small training size, so that the amortization network can not be trained well. We generally wouldn&#x27;t recommend to use spatial deconvolution techniques for such low number of spots. Given the higher stability over a various number of mini-batch sizes, we prefer to recommend using both amortization scheme. In cases with very few examples and known ground-truth we advise training both models and comparing the results.</p><img alt="STARmap_sub" width="100%" src="/img/blog-post-destvi-batchsize/STARmap_sub.png"><p>Figure 3: Results on subset of benchmarking dataset. Subset on first three columns in original dataset. Displayed are only neuron layers as structure in other celltypes is hardly detected with only three columns. For ground-truth, we display all columns to allow easier comparison. Left-to-right ground truth, Cell2Location, DestVI with both amortization and batch-size 4, 8, 12, 16, 32 and DestVI with latent amortization with same batch size. On par performance with mini-batch size 4 and latent amortization is visible with slightly reduced performance in both amortization.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="results-on-merfish-dataset"></a>Results on MERFISH dataset<a class="hash-link" href="#results-on-merfish-dataset" title="Direct link to heading">#</a></h3><p>To check the effect of training mini-batch size on the performance of large datasets, we simulated a second pseudospot matrix. The training time increases drastically with reducing the mini-batch size as the GPU is used less efficiently. We therefore restricted to models with a mini-batch size above 32 (trained more than 3 hours on a Nvidia RTX 3090). We therefore think that the mini-batch size should be 128, in which case we haven&#x27;t seen major speed improvement (most likely depends on the GPU architecture).</p><table><thead><tr><th>model</th><th>computation time</th></tr></thead><tbody><tr><td>Cell2location</td><td>2h 3min 13s</td></tr><tr><td>batchsize_32 both_amortization</td><td>3h 31min 27s</td></tr><tr><td>batchsize_48 both_amortization</td><td>1h 44min 21s</td></tr><tr><td>batchsize_64 both_amortization</td><td>1h 26min 5s</td></tr><tr><td>batchsize_128 both_amortization</td><td>36min 17s</td></tr><tr><td>batchsize_256 both_amortization</td><td>20min 48s</td></tr><tr><td>batchsize_512 both_amortization</td><td>10min 55s</td></tr><tr><td>batchsize_1024 both_amortization</td><td>10min 03s</td></tr></tbody></table><p>Overall, for all combinations of parameters we see improved performance of destVI over standard Cell2Location. This is especially visible in Di- and mesencephalon excitatory neurons and Telencephalon inhibitory inter-neurons where Cell2Location doesn&#x27;t uncover the tissue distribution of this cell-type. We see here no correlation to small size of those cell-types, and the reason for this reduced performance is not clear. As we haven&#x27;t set out a benchmarking study here, but to study the performance of destVI, we haven&#x27;t changed the hyper-parameters for Cell2Location to increase performance.</p><table><thead><tr><th>cell-type</th><th>freq_sc</th><th>freq_spatial</th></tr></thead><tbody><tr><td>Oligodendrocytes</td><td>30253</td><td>10244</td></tr><tr><td>Astrocytes</td><td>19377</td><td>9476</td></tr><tr><td>Telencephalon projecting exc. neurons</td><td>18799</td><td>22345</td></tr><tr><td>Telencephalon inh. interneurons</td><td>8637</td><td>4451</td></tr><tr><td>Mesencephalon exc. neurons</td><td>6455</td><td>8066</td></tr><tr><td>TE proj. inh. neurons</td><td>5691</td><td>3569</td></tr><tr><td>Microglia</td><td>5425</td><td>477</td></tr><tr><td>Vascular endothelial cells</td><td>3805</td><td>6188</td></tr><tr><td>Vascular smooth muscle cells</td><td>1628</td><td>2018</td></tr><tr><td>Vascular and leptomeningeal cells</td><td>1501</td><td>1905</td></tr><tr><td>Ependymal cells</td><td>1257</td><td>900</td></tr><tr><td>Hindbrain neurons</td><td>1144</td><td>43</td></tr><tr><td>Cholinergic and monoaminergic neurons</td><td>1071</td><td>6163</td></tr><tr><td>Oligodendrocyte precursor cells</td><td>820</td><td>4524</td></tr><tr><td>Choroid epithelial cells</td><td>458</td><td>477</td></tr></tbody></table><p>Overall we see that performance is stable up to a batch size of 256 with decreasing performance for both amortization and batch size 512 and 1,024, while performance of latent amortization is stable with increasing batch size. We postulate that mini-batch training of the cell-type amortization network is essential for performance. As above we have seen speed improvement by using a bigger batch size, we asked whether bigger batch sizes are good in performance, when we train them for more epochs. Indeed increasing the number of epochs for mini-batch size 512 lead to on par performance using 5,000 instead of the default 2,500 training epochs, while performance of mini-batch size 1,024 was still inferior when checking with 10,000 training epochs.</p><img alt="MERFISH" width="100%" src="/img/blog-post-destvi-batchsize/MERFISH2.png"><p>Figure 4: Results on MERFISH brain dataset. Left-to-right ground truth, Cell2Location, DestVI with both amortization and batch-size 32, 128, 256, 1,024 and DestVI with latent amortization with same batch size. Cell type proportion estimates are improved over Cell2Location in all destVI models. There is a decrease in performance for models with batch_size 1,024 for endothelial cells, that are low abundant in every spot.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="conclusion"></a>Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">#</a></h2><p>In the analysis of destVI from the main paper, we had limited our benchmarking to standard spot based assays, in which both spatial and single cell data sets are based on whole transcriptome sequencing and especially contain more than 1,000 spots. We found that DestVI performance from the newly published benchmarking study was mediocre because the number of spots was close to the training mini-batch size and therefore the underlying composition of the spots was not learned adequately. We verified this by proving that by decreasing training mini-batch size, destVI can yield on par performance to other methods for cell type deconvolution.</p><p>DestVI yields not only cell-type proportion estimates but also cell-type activation estimates, the benchmarking study was designed to only study cell-type proportion estimates and we kept the same design here. Generally, we think the additional output of cell-type activation is a major benefit of DestVI over competing algorithms. We nevertheless thank the authors of the original benchmarking study to discover deficiencies of destVI with small number of spots.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_31ik" id="practical-recommendations"></a>Practical recommendations<a class="hash-link" href="#practical-recommendations" title="Direct link to heading">#</a></h4><p>We demonstrated that destVI also yields those results with a subset of the original dataset with just 57 spots. We also checked 19 spots here and destVI and Cell2Location weren&#x27;t discovering the different layers of cortical neurons. We therefore recommend users to not run destVI with less than 50 spots.</p><p>Over the course of our experiments, we found a training mini-batch size of max(dataset_size/10, 128) to perform well in deconvolution. We set the maximum batch size to 128 as we saw decreasing performance with a batch size of 512 for the brain dataset. Most likely it is safe to increase the mini-batch size for big datasets and getting runtime benefits. However, we have most experience from experiments with a batch size of 128 and limit the maximum batch size to this value. If runtime is a big concern, manual increase of this parameter is possible. The version with batchsize 128 was already several times faster than Cell2Location.</p><p>DestVI with latent amortization showed superior performance in the setting with optimal mini-batch size in small datasets but performance was inferior for other mini-batch sizes. We continue suggesting both amortization and in the case of the brain dataset both amortization schemes were similar in performance.</p><p>Please share any feedback with us via twitter (@YosefLab), through the comment section below or through scverse discourse webpage (<a href="https://discourse.scverse.org/" target="_blank" rel="noopener noreferrer">https://discourse.scverse.org/</a>).</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="acknowledgements"></a>Acknowledgements<a class="hash-link" href="#acknowledgements" title="Direct link to heading">#</a></h2><p>We acknowledge members of the Yosef Lab. We thank Adam Gayoso for reviewing the changes to destVI and bringing the benchmarking study to our attention.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="bibliography"></a>Bibliography<a class="hash-link" href="#bibliography" title="Direct link to heading">#</a></h2><p>(1) Romain Lopez, Baoguo Li, Hadas Keren-Shaul, Pierre Boyeau, Merav Kedmi, David Pilzer, Adam Jelinski, Ido Yofe, Eyal David, Allon Wagner, Can Ergen, Yoseph Addadi, Ofra Golani, Franca Ronchese, Michael I. Jordan, Ido Amit and Nir Yosef. DestVI identifies continuums of cell types in spatial transcriptomics data. Nature Biotechnology. 2022.</p><p>(2) Vitalii Kleshchevnikov, Artem Shmatko, Emma Dann, Alexander Aivazidis, Hamish W. King, Tong Li, Rasa Elmentaite, Artem Lomakin, Veronika Kedlian, Adam Gayoso, Mika Sarkin Jain, Jun Sung Park, Lauma Ramona, Elizabeth Tuck, Anna Arutyunyan, Roser Vento-Tormo, Moritz Gerstung, Louisa James, Oliver Stegle and Omer Ali Bayraktar.  Cell2location maps fine-grained cell types in spatial transcriptomics. Nature Biotechnology. 2022.</p><p>(3) Bin Li, Wen Zhang, Chuang Guo, Hao Xu, Longfei Li, Minghao Fang, Yinlei Hu, Xinye Zhang, Xinfeng Yao, Meifang Tang, Ke Liu, Xuetong Zhao, Jun Lin, Linzhao Cheng, Falai Chen, Tian Xue and Kun Qu. Benchmarking spatial and single-cell transcriptomics integration methods for transcript distribution prediction and cell type deconvolution. Nature Methods. 2022.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/blog/tags/destvi">destvi</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/blog/tags/batch-size">batch-size</a></li></ul></div><div class="col col--3 text--right"><a aria-label="Read more about Mini-batch size in destVI" href="/blog/destvi-batchsize"><b>Read More</b></a></div></footer></article></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025, Yosef Lab, Weizmann Institute of Science. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.a95fbbf9.js"></script>
<script src="/assets/js/main.5868d4e3.js"></script>
</body>
</html>