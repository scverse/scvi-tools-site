<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="scvi-tools Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="scvi-tools Blog Atom Feed">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><title data-react-helmet="true">Blog | scvi-tools</title><meta data-react-helmet="true" property="og:title" content="Blog | scvi-tools"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="description" content="Blog"><meta data-react-helmet="true" property="og:description" content="Blog"><meta data-react-helmet="true" property="og:url" content="https://scvi-tools.org/blog"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="blog_posts_list"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://scvi-tools.org/blog"><link data-react-helmet="true" rel="alternate" href="https://scvi-tools.org/blog" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://scvi-tools.org/blog" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.34d598f1.css">
<link rel="preload" href="/assets/js/runtime~main.1b571c78.js" as="script">
<link rel="preload" href="/assets/js/main.19b51a5d.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/logo.svg" alt="scvi-tools Logo" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/img/logo.svg" alt="scvi-tools Logo" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">scvi-tools</b></a></div><div class="navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/get_started">Get Started</a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link">Docs</a><ul class="dropdown__menu"><li><a href="https://docs.scvi-tools.org" target="_self" rel="noopener noreferrer" class="dropdown__link"><span>Full documentation<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li><a href="https://docs.scvi-tools.org/en/stable/tutorials/index.html" target="_self" rel="noopener noreferrer" class="dropdown__link"><span>Tutorials<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li><a href="https://docs.scvi-tools.org/en/stable/user_guide/index.html" target="_self" rel="noopener noreferrer" class="dropdown__link"><span>User guide<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li><a href="https://docs.scvi-tools.org/en/stable/api/index.html" target="_self" rel="noopener noreferrer" class="dropdown__link"><span>API reference<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link">About</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/team">Team</a></li><li><a class="dropdown__link" href="/press">Press</a></li><li><a class="dropdown__link" href="/ecosystem">Ecosystem</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a href="https://discourse.scvi-tools.org/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>Discussion<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><a href="https://github.com/YosefLab/scvi-tools" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper blog-wrapper blog-list-page"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_2ahu thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_2hhb margin-bottom--md">Recent posts</div><ul class="sidebarItemList_2xAf"><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/2025/3/7/scvi-tools-v1p3">scvi-tools-v1p3</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/destvi-batchsize">Mini-batch size in destVI</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/v090">scvi-tools 0.9.0 release</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/autotune">Hyperparameter search for scVI</a></li><li class="sidebarItem_2UVv"><a class="sidebarItemLink_1RT6" href="/blog/zero-inflation">Should we zero-inflate scVI?</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/blog/2025/3/7/scvi-tools-v1p3">scvi-tools-v1p3</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2025-03-07T00:00:00.000Z" itemprop="datePublished">March 7, 2025</time> ¬∑ 5 min read</div></header><div class="markdown" itemprop="articleBody"><hr><p>slug: v13
title:      Scvi‚ÄëTools v1.3: Next‚ÄëGen Models, Scalable Data Handling &amp; Core Enhancements
date:       2025‚Äë07‚Äë03
author: Ori Kronfeld</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="tags-scvi-tools-release"></a>tags: [scvi-tools, release]<a class="hash-link" href="#tags-scvi-tools-release" title="Direct link to heading">#</a></h2><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="introduction"></a>Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">#</a></h2><p>We‚Äôre proud to introduce <strong>scvi‚Äëtools v1.3</strong> (releases 1.3.0 through 1.3.2), encompassing major advances in modeling, data loading, computational scalability, metric integration, and interpretability. This release spans nine new or enhanced models‚Äîtailored to spatial, cytometry, methylation, perturbation, and multi‚Äëomic studies‚Äîalongside support for streaming large datasets, multi‚ÄëGPU training, scIB metric optimization, and integrated model explainability. Here‚Äôs a detailed walkthrough.</p><hr><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="1--new-models"></a>1. üî¨ New Models<a class="hash-link" href="#1--new-models" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="resolvi"></a><strong>ResolVI</strong><a class="hash-link" href="#resolvi" title="Direct link to heading">#</a></h3><p>ResolVI is a probabilistic model specifically designed to denoise cellular-resolution spatial transcriptomics by reallocating misassigned genes between true cells, neighbor-derived leakage, and background noise. It builds a mixture-of-Gaussians latent prior and reconstructs both corrected counts and embeddings. This approach is highly scalable (handling &gt;1 million spots) and offers downstream capabilities like differential expression and transfer learning on corrected data :contentReference[oaicite:1]{index=1}.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="scviva"></a><strong>scVIVA</strong><a class="hash-link" href="#scviva" title="Direct link to heading">#</a></h3><p>scVIVA augments spatial transcriptomics analysis by jointly modeling each cell‚Äôs own expression and its micro-environmental context (neighborhood composition and gene counts). This niche-aware VAE embeds both cellular identity and environmental features, revealing tissue-specific patterns and environment-driven variation. Dedicated tutorials showcase how scVIVA enables niche-focused clustering and differential abundance analyses :contentReference[oaicite:2]{index=2}.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="cytovi"></a><strong>CytoVI</strong><a class="hash-link" href="#cytovi" title="Direct link to heading">#</a></h3><p>CytoVI adapts the totalVI architecture for cytometry and mass cytometry data, focusing on protein marker distribution and batch correction. By modeling dropout and technical variation intrinsic to protein measurements, CytoVI delivers embeddings optimized for clustering and differential abundance studies. Early tutorials already demonstrate clear delineation of immune subpopulations across batch-affected datasets.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="vivs"></a><strong>VIVS</strong><a class="hash-link" href="#vivs" title="Direct link to heading">#</a></h3><p>Variational Inference for Variable Selection (VIVS) identifies associations across modalities‚Äîsuch as gene‚Äìprotein couplings‚Äîwhile rigorously controlling false discovery rates using conditional randomization. Demonstrated in Genome Biology, VIVS achieves interpretable and scalable feature selection, enabling discovery of biologically meaningful links in paired datasets :contentReference[oaicite:3]{index=3}.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="sysvi"></a><strong>SysVI</strong><a class="hash-link" href="#sysvi" title="Direct link to heading">#</a></h3><p>SysVI tackles challenging integration scenarios‚Äîsuch as reconciling data across species or organoid systems‚Äîby combining latent cycle-consistency with a VampPrior. Benchmarks show that SysVI outperforms prior approaches like scVI and Harmony by preserving biological variability while robustly aligning batch-specific effects :contentReference[oaicite:4]{index=4}.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="decipher"></a><strong>Decipher</strong><a class="hash-link" href="#decipher" title="Direct link to heading">#</a></h3><p>Decipher is tailored for perturbation studies (e.g., disease vs. control), learning a latent structure that separates shared from condition-specific signals. When applied to AML datasets, Decipher identifies known markers and distinct latent dimensions corresponding to disease status, supported by new tutorials and API references :contentReference[oaicite:5]{index=5}.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="methylvi"></a><strong>MethylVI</strong><a class="hash-link" href="#methylvi" title="Direct link to heading">#</a></h3><p>This VAE-based framework is devoted to single-cell bisulfite sequencing (scBS-seq) data. MethylVI models the probability of methylation at individual cytosine sites and learns an interpretable cell latent space. Its tutorial demonstrates that it outperforms PCA-based methods for consistent batch integration across multiple BS-seq experiments :contentReference[oaicite:6]{index=6}.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="methylanvi--totalanvi"></a><strong>MethylANVI &amp; totalANVI</strong><a class="hash-link" href="#methylanvi--totalanvi" title="Direct link to heading">#</a></h3><p>These annotation-aware models integrate multi-omic modalities with supervised cell-type labeling. totalANVI extends totalVI to jointly model RNA and protein expression while learning cell-type labels. MethylANVI brings the same framework to methylation and RNA joint datasets. Both models support unified annotation, clustering, and differential testing under one model :contentReference[oaicite:7]{index=7}.</p><hr><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="2-üß©-custom-dataloaders"></a>2. üß© Custom Dataloaders<a class="hash-link" href="#2-üß©-custom-dataloaders" title="Direct link to heading">#</a></h2><p>v1.3 introduces three new <strong>streaming dataloader backends</strong>, allowing large or federated datasets to be handled efficiently without loading everything into memory:</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="lamindb"></a><strong>LaminDB</strong><a class="hash-link" href="#lamindb" title="Direct link to heading">#</a></h3><p>Integrates with Lamindb, enabling out-of-core training from disk-backed collections. Users can register collections and seamlessly train models like SCVI, benefiting from disk efficiency while maintaining full API compatibility with in-memory datasets :contentReference[oaicite:8]{index=8}.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="census"></a><strong>Census</strong><a class="hash-link" href="#census" title="Direct link to heading">#</a></h3><p>Built on TileDB and optimized for atlas-scale data, Census dataloaders support streaming of massive datasets. The API mirrors LaminDB, promoting scalability without code changes in modeling pipelines :contentReference[oaicite:9]{index=9}.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="anncollection"></a><strong>AnnCollection</strong><a class="hash-link" href="#anncollection" title="Direct link to heading">#</a></h3><p>Allows training on multiple AnnData objects simultaneously, without merging them into one dataset. AnnCollection handles disparities in features or layers internally and aligns them during training, empowering federated or multi-study analyses‚Äîdetailed in tutorial PR #450 :contentReference[oaicite:10]{index=10}.</p><hr><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="3-Ô∏è-technical-enhancements"></a>3. ‚öôÔ∏è Technical Enhancements<a class="hash-link" href="#3-Ô∏è-technical-enhancements" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="multigpu-training"></a>Multi‚ÄëGPU Training<a class="hash-link" href="#multigpu-training" title="Direct link to heading">#</a></h3><p>Leveraging PyTorch Lightning, scvi‚Äëtools now supports multi‚ÄëGPU training with simple API flags. Official examples demonstrate 2‚Äì3√ó throughput improvements on 1 million cell datasets, enabling practical training of massive single-cell models :contentReference[oaicite:11]{index=11}.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="scibmetrics-optimization"></a>scIB‚ÄëMetrics Optimization<a class="hash-link" href="#scibmetrics-optimization" title="Direct link to heading">#</a></h3><p>With the integration of <code>ScibCallback</code> and the <code>AutotuneExperiment</code> class, users can now monitor scIB metrics (like NMI and batch ARI) on the validation set during training and automatically tune hyperparameters (latent dimensions, learning rate) based on these metrics‚Äîdirectly optimizing for clustering and batch mixing performance :contentReference[oaicite:12]{index=12}.</p><hr><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="explainability--interpretability"></a>Explainability &amp; Interpretability<a class="hash-link" href="#explainability--interpretability" title="Direct link to heading">#</a></h3><p>scvi‚Äëtools now supports <strong>Integrated Gradients</strong> for many models, enabling gene-level attribution of latent features. Coupled with <code>get_normalized_expression</code> for batch‚Äëcorrected expression recovery, this framework allows researchers to interpret latent dimensions in terms of known gene drivers‚Äîoffering transparency in deep generative modeling :contentReference[oaicite:13]{index=13}.</p><hr><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="summary"></a>Summary<a class="hash-link" href="#summary" title="Direct link to heading">#</a></h2><p>scvi‚Äëtools v1.3 stands as a landmark release across three domains:  </p><ul><li><strong>New generative models</strong> suited to spatial, cytometry, multi‚Äëomic, methylation, and perturbation data;  </li><li><strong>Streaming dataloaders</strong> (LaminDB, Census, AnnCollection) for large-scale or federated datasets;  </li><li><strong>Core capabilities</strong> including multi-GPU scaling, metric-driven hyperparameter tuning, and model interpretability.</li></ul><p>Taken together, these enhancements empower scientists to efficiently build, interpret, and deploy deep single-cell workflows at previously unprecedented scale and clarity.</p><hr><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="references"></a>References<a class="hash-link" href="#references" title="Direct link to heading">#</a></h2><ul><li>ResolVI spatial denoising tutorial &amp; model description :contentReference[oaicite:14]{index=14}  </li><li>scVIVA niche-aware spatial modeling tutorial :contentReference[oaicite:15]{index=15}  </li><li>VIVS feature-selection in Genome Biology 2024 :contentReference[oaicite:16]{index=16}  </li><li>SysVI, Decipher, and methylVI/ANVI model overview in user guide :contentReference[oaicite:17]{index=17}  </li><li>Dataloader benchmarking and Lamindb/Census workflows :contentReference[oaicite:18]{index=18}  </li><li>Multi-GPU &amp; scIB metrics tutorials :contentReference[oaicite:19]{index=19}  </li><li>Integrated Gradients and explainability tutorials :contentReference[oaicite:20]{index=20}</li></ul></div></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/blog/destvi-batchsize">Mini-batch size in destVI</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2022-05-29T00:00:00.000Z" itemprop="datePublished">May 29, 2022</time> ¬∑ 15 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a itemprop="url"><span itemprop="name">Can Ergen, Romain Lopez, Nir Yosef</span></a></div></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>The task of deconvolution of spot-based spatial transcriptomics (ST) data consists in finding the cellular composition in spots of ST assays. Indeed, by design each spot consists of several individual cells. Our lab developed destVI as a tool to study cell type composition of spots (1). In the case where one expects within cell type variation (i.e., activation states), DestVI was designed to infer the activation state of individual cell types in each spot and therefore gives additional resolution of cell composition over competing algorithms. In our own benchmarking of destVI, we found comparable performance in prediction of cell type proportions to other state of the art algorithms like Cell2Location (2). A recent benchmarking study compared the performance of several gene imputation as well as deconvolution methods. Given the ever increasing number of deconvolution methods, the effort to benchmark those tools on a variety of simulated data is timely (3). In two of the benchmarking cases, DestVI had the worst performance. Along with the recent acceptance of the manuscript, we published several fixes to the codebase in scvi-tools v0.16.0, repeated those experiments and analyzed the reasons for failure of spot deconvolution in the given experiments. Briefly, we show that the poor performance was due to the mini-batch size used during optimization, and resolving this help recovering competitive accuracy. Additionally, we provide the user with a heuristic for future use.</p><p>More specifically, variational autoencoders are a specific type of neural networks (NN) that, like most NN, are trained by iteratively presenting the network mini-batches of data, that is a small fraction of the whole dataset. The mini-batch size refers to number of distinct samples used for updating the parameters of the neural networks during one training step.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="methodology"></a>Methodology<a class="hash-link" href="#methodology" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="models"></a>Models<a class="hash-link" href="#models" title="Direct link to heading">#</a></h3><p>The DestVI model (1) uses a first training phase on a reference single cell dataset to learn a cell-type specific latent space. Then, it learns a second model using as input the spot data, and encoding them in the reference latent space. Finally, the model learns cell-type proportions for each spot. In this blog post, we only address the cell-type proportion estimate as was done in the original benchmarking study (3). We haven&#x27;t checked the activation state of those cells as the simulation was designed in a way where the mean activation state of each cell-type in each spot is not known and ground-truth therefore is missing. For all experiments here, we kept the parameters for the CondSCVI model on which the single-cell data is learned constant and highlight every parameter we changed in the respective run. The only two parameters that we highlight here are the amortization scheme, where destVI allows a neural network for amortization of cell-type proportions and activation state or models them as free parameters, and the mini-batch size used for training.</p><p>The selection of genes for destVI used in the original benchmarking study is a point we wanted to mention here. The authors first took the intersection of the genes in spatial assay and single cell assay (882 genes overlapping for STARmap dataset) and then took the 2000 highly variable genes. This second step was without effect (2000 is higher than 882). Nevertheless, in case a FISH based experiments was designed specifically for an organ and all genes were carefully selected, we generally would recommend against additional filtering for over-dispersed genes in a single cell reference but train the model directly on the overlap of spatial and single cell genes skipping the step of highly variable genes.</p><p>We compare destVI throughout this blog post with the benchmark version of Cell2Location. Our purpose is not to prove that we outperform other existing methods but to analyze why destVI showed poor performance in the benchmarking study. Cell2Location showed overall good performance in the benchmarking study and is implemented using the scvi-tools framework but relies on a marker gene related approach instead of an unbiased deconvolution approach.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="hyperparameter-selection"></a>Hyperparameter selection<a class="hash-link" href="#hyperparameter-selection" title="Direct link to heading">#</a></h3><p>Most experiments before the destVI publication, as well as the benchmarking study were performed using cell-type activation state amortization only (called latent amortization hereafter) and treat the cell-type proportions as a free parameter. However, in the recent version of the code we generally recommend to use the amortized version of both (called both amortization hereafter). In this blog post, we checked performance in all experiments here for both amortization schemes. The size of the training mini-batch size varied as {4, 8, 16, 32, 64, 128, 256, 512, 1024}. For comparison with the benchmarking study we left out batch sizes 256 or higher because the number of spots was 189. For our comparison, in a large scale dataset we left out batch_sizes 16 and lower because the training time drastically increases when using small batch sizes on large datasets.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="results"></a>Results<a class="hash-link" href="#results" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="datasets"></a>Datasets<a class="hash-link" href="#datasets" title="Direct link to heading">#</a></h3><p>We reused the STARmap dataset from the original publication (mouse brain cortex). The single-cell reference contains 14,249 cells by 34,041 genes. It contains data from several mouse lines, both sexes and from various time points that were sorted by flow cytometry and sequentially sequenced. The STARmap dataset contains 1,523 cells by 981 genes. The simulation is to sum all counts over a window size of 750 pixels. This gives a pseudo-spot count matrix with 189 spots and 1-17 cells per spot. For further reference, we refer to the original publication (3). We subset this dataset to 57 spots to see how destVI performs in the case of even lower number of spots by subsetting this data to the first three column as diversity of cell-types is mainly along the cortical axis and subsetting to columns keeps the complexity of the dataset similar.</p><p>For a regime with more spots, we decided to keep the organ of interest (mouse brain) and use a dataset with a much higher number of cell captured. We reproduced for this matter the analysis provided by Vizgen using MERFISH technology, which provides a walk-through tutorial on Google Colab.</p><img alt="MERFISH_data" width="100%" src="/img/blog-post-destvi-batchsize/vizgen_colab.png"><p>Figure 1: Overview of MERFISH brain dataset from (<a href="https://colab.research.google.com/drive/1OxJRO19cPsDW0JGAh4tLJjgOl7EMxQbP?usp=sharing&amp;__hstc=30510752.37206d737856c71bb0a5d1c8f6764b63.1652985789816.1653807477271.1653882474080.8&amp;__hssc=30510752.1.1653882474080&amp;__hsfp=455698764&amp;hsCtaTracking=070f4af1-2595-44c8-9779-4da89d538482%7Cf4313de5-25c4-4677-9fd6-82cf71d4fdc4" target="_blank" rel="noopener noreferrer">https://colab.research.google.com/drive/1OxJRO19cPsDW0JGAh4tLJjgOl7EMxQbP?usp=sharing&amp;__hstc=30510752.37206d737856c71bb0a5d1c8f6764b63.1652985789816.1653807477271.1653882474080.8&amp;__hssc=30510752.1.1653882474080&amp;__hsfp=455698764&amp;hsCtaTracking=070f4af1-2595-44c8-9779-4da89d538482%7Cf4313de5-25c4-4677-9fd6-82cf71d4fdc4</a>).</p><p>This analysis yields a single-cell reference dataset with 160,796 cells by 27,998 genes and a spatial dataset with 83,546 cells by 483 genes. The simulation here is again to sum all counts of cells with a center over a window of 40 ¬µm. We choose the size of this window to have an equal number of cells per pseudo-spot compared to the STARmap dataset. This gives a pseudo-spot count matrix with 27395 spots and 1-16 cells per spot.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="results-on-starmap-dataset"></a>Results on STARmap dataset<a class="hash-link" href="#results-on-starmap-dataset" title="Direct link to heading">#</a></h3><p>First, we verified that by using the updated version of the code in scvi-tools v0.16.0, we get similar results to the benchmarking study. In agreement with the original benchmarking study, the layer structure of neurons in different cortical layers wasn&#x27;t visible.</p><p>Then, we ran different amortization variants of DestVI. Modeling cell-type proportions as a free parameter leads to no visible structure at all (as was run by the study). When using amortized cell-type proportions, which uses a neural network to estimate cell-type proportions, destVI predicted astrocytes correctly, while it wasn&#x27;t capable of differentiating different excitatory neurons but were classifying all neurons as a single mixture.</p><p>By changing the batch-size, we noticed that decreasing the training mini-batch size drastically improves the performance of both algorithms.  Notably, the model with a mini-batch size of 32 and both parameters amortized performs badly. We see good deconvolution of the different neuronal layers with a batch size of 8, 12 and 16. Additionally, for these batch size there was no qualitative difference between both amortization and latent amortization.</p><p>When comparing the results of destVI with Cell2Location it becomes clear that Cell2Location outperforms destVI for cell-types like Pvalp or Smc cells while both algorithms fail on microglia. The reason for better performance of Cell2Location is most likely low number of those cell-types in the spatial dataset and therefore low percentage in the respective spot. The bad performance for microglia might be based on the selection of FISH probes giving a low coverage of myeloid cell heterogeneity.</p><img alt="STARmap" width="100%" src="/img/blog-post-destvi-batchsize/STARmap.png"><p>Figure 2: Results on benchmarking dataset. Left-to-right ground truth, Cell2Location, DestVI with both amortization and batch-size 8, 16, 48, 128 and DestVI with latent amortization with same batch size. Increase in matching proportions for destVI with decreasing mini-batch size. Cell2Location outperforms destVI for Oligodendrocytes. Quantitative measurues (PCC=Pearson Correlation Coefficient, SSIM=Structural Similarity, RMSE=Root Mean Squared Error, JSD=Jensen-Shannon-Divergence) show on par performance for destVI with a mini-batch size below 16.</p><table><thead><tr><th>cell-type</th><th>freq_sc</th><th>freq_spatial</th></tr></thead><tbody><tr><td>ExcitatoryL6</td><td>3190</td><td>287</td></tr><tr><td>ExcitatoryL5</td><td>1786</td><td>94</td></tr><tr><td>Sst</td><td>1741</td><td>42</td></tr><tr><td>Vip</td><td>1728</td><td>15</td></tr><tr><td>ExcitatoryL4</td><td>1401</td><td>198</td></tr><tr><td>Pvalb</td><td>1337</td><td>42</td></tr><tr><td>ExcitatoryL2and3</td><td>982</td><td>258</td></tr><tr><td>Astro</td><td>368</td><td>141</td></tr><tr><td>Endo</td><td>94</td><td>150</td></tr><tr><td>Olig</td><td>91</td><td>200</td></tr><tr><td>Smc</td><td>55</td><td>13</td></tr><tr><td>Micro</td><td>51</td><td>23</td></tr></tbody></table><p>When checking quantitative results, we find on par performance of destVI and Cell2Location in Pearson Correlation Coefficient based on spots while when checking for correlation across cell-types Cell2Location outperforms destVI. The reason for this improved performance are as described above lowly abundant cell-types.</p><p>As demonstrated here, by reducing the size of the training mini-batch destVI yields overall similar performance to Cell2Location for cell-type deconvolution. We asked next whether this is also the case when even further reducing the number of spots. For this study, as described above we subset the number of pseudo-spots and retrained Cell2Location and destVI. Overall, we find better agreement with both amortization for different sizes of training batch size. Oligodendrocytes and Astrocytes are correctly predicted in all version with both amortization. Only the models with a batch size of 4 differentiate between the different layers of excitatory neurons. Of note, latent amortization outperforms both amortization here for a mini-batch size of 4. It might be an effect of small training size, so that the amortization network can not be trained well. We generally wouldn&#x27;t recommend to use spatial deconvolution techniques for such low number of spots. Given the higher stability over a various number of mini-batch sizes, we prefer to recommend using both amortization scheme. In cases with very few examples and known ground-truth we advise training both models and comparing the results.</p><img alt="STARmap_sub" width="100%" src="/img/blog-post-destvi-batchsize/STARmap_sub.png"><p>Figure 3: Results on subset of benchmarking dataset. Subset on first three columns in original dataset. Displayed are only neuron layers as structure in other celltypes is hardly detected with only three columns. For ground-truth, we display all columns to allow easier comparison. Left-to-right ground truth, Cell2Location, DestVI with both amortization and batch-size 4, 8, 12, 16, 32 and DestVI with latent amortization with same batch size. On par performance with mini-batch size 4 and latent amortization is visible with slightly reduced performance in both amortization.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="results-on-merfish-dataset"></a>Results on MERFISH dataset<a class="hash-link" href="#results-on-merfish-dataset" title="Direct link to heading">#</a></h3><p>To check the effect of training mini-batch size on the performance of large datasets, we simulated a second pseudospot matrix. The training time increases drastically with reducing the mini-batch size as the GPU is used less efficiently. We therefore restricted to models with a mini-batch size above 32 (trained more than 3 hours on a Nvidia RTX 3090). We therefore think that the mini-batch size should be 128, in which case we haven&#x27;t seen major speed improvement (most likely depends on the GPU architecture).</p><table><thead><tr><th>model</th><th>computation time</th></tr></thead><tbody><tr><td>Cell2location</td><td>2h 3min 13s</td></tr><tr><td>batchsize_32 both_amortization</td><td>3h 31min 27s</td></tr><tr><td>batchsize_48 both_amortization</td><td>1h 44min 21s</td></tr><tr><td>batchsize_64 both_amortization</td><td>1h 26min 5s</td></tr><tr><td>batchsize_128 both_amortization</td><td>36min 17s</td></tr><tr><td>batchsize_256 both_amortization</td><td>20min 48s</td></tr><tr><td>batchsize_512 both_amortization</td><td>10min 55s</td></tr><tr><td>batchsize_1024 both_amortization</td><td>10min 03s</td></tr></tbody></table><p>Overall, for all combinations of parameters we see improved performance of destVI over standard Cell2Location. This is especially visible in Di- and mesencephalon excitatory neurons and Telencephalon inhibitory inter-neurons where Cell2Location doesn&#x27;t uncover the tissue distribution of this cell-type. We see here no correlation to small size of those cell-types, and the reason for this reduced performance is not clear. As we haven&#x27;t set out a benchmarking study here, but to study the performance of destVI, we haven&#x27;t changed the hyper-parameters for Cell2Location to increase performance.</p><table><thead><tr><th>cell-type</th><th>freq_sc</th><th>freq_spatial</th></tr></thead><tbody><tr><td>Oligodendrocytes</td><td>30253</td><td>10244</td></tr><tr><td>Astrocytes</td><td>19377</td><td>9476</td></tr><tr><td>Telencephalon projecting exc. neurons</td><td>18799</td><td>22345</td></tr><tr><td>Telencephalon inh. interneurons</td><td>8637</td><td>4451</td></tr><tr><td>Mesencephalon exc. neurons</td><td>6455</td><td>8066</td></tr><tr><td>TE proj. inh. neurons</td><td>5691</td><td>3569</td></tr><tr><td>Microglia</td><td>5425</td><td>477</td></tr><tr><td>Vascular endothelial cells</td><td>3805</td><td>6188</td></tr><tr><td>Vascular smooth muscle cells</td><td>1628</td><td>2018</td></tr><tr><td>Vascular and leptomeningeal cells</td><td>1501</td><td>1905</td></tr><tr><td>Ependymal cells</td><td>1257</td><td>900</td></tr><tr><td>Hindbrain neurons</td><td>1144</td><td>43</td></tr><tr><td>Cholinergic and monoaminergic neurons</td><td>1071</td><td>6163</td></tr><tr><td>Oligodendrocyte precursor cells</td><td>820</td><td>4524</td></tr><tr><td>Choroid epithelial cells</td><td>458</td><td>477</td></tr></tbody></table><p>Overall we see that performance is stable up to a batch size of 256 with decreasing performance for both amortization and batch size 512 and 1,024, while performance of latent amortization is stable with increasing batch size. We postulate that mini-batch training of the cell-type amortization network is essential for performance. As above we have seen speed improvement by using a bigger batch size, we asked whether bigger batch sizes are good in performance, when we train them for more epochs. Indeed increasing the number of epochs for mini-batch size 512 lead to on par performance using 5,000 instead of the default 2,500 training epochs, while performance of mini-batch size 1,024 was still inferior when checking with 10,000 training epochs.</p><img alt="MERFISH" width="100%" src="/img/blog-post-destvi-batchsize/MERFISH2.png"><p>Figure 4: Results on MERFISH brain dataset. Left-to-right ground truth, Cell2Location, DestVI with both amortization and batch-size 32, 128, 256, 1,024 and DestVI with latent amortization with same batch size. Cell type proportion estimates are improved over Cell2Location in all destVI models. There is a decrease in performance for models with batch_size 1,024 for endothelial cells, that are low abundant in every spot.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="conclusion"></a>Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">#</a></h2><p>In the analysis of destVI from the main paper, we had limited our benchmarking to standard spot based assays, in which both spatial and single cell data sets are based on whole transcriptome sequencing and especially contain more than 1,000 spots. We found that DestVI performance from the newly published benchmarking study was mediocre because the number of spots was close to the training mini-batch size and therefore the underlying composition of the spots was not learned adequately. We verified this by proving that by decreasing training mini-batch size, destVI can yield on par performance to other methods for cell type deconvolution.</p><p>DestVI yields not only cell-type proportion estimates but also cell-type activation estimates, the benchmarking study was designed to only study cell-type proportion estimates and we kept the same design here. Generally, we think the additional output of cell-type activation is a major benefit of DestVI over competing algorithms. We nevertheless thank the authors of the original benchmarking study to discover deficiencies of destVI with small number of spots.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_31ik" id="practical-recommendations"></a>Practical recommendations<a class="hash-link" href="#practical-recommendations" title="Direct link to heading">#</a></h4><p>We demonstrated that destVI also yields those results with a subset of the original dataset with just 57 spots. We also checked 19 spots here and destVI and Cell2Location weren&#x27;t discovering the different layers of cortical neurons. We therefore recommend users to not run destVI with less than 50 spots.</p><p>Over the course of our experiments, we found a training mini-batch size of max(dataset_size/10, 128) to perform well in deconvolution. We set the maximum batch size to 128 as we saw decreasing performance with a batch size of 512 for the brain dataset. Most likely it is safe to increase the mini-batch size for big datasets and getting runtime benefits. However, we have most experience from experiments with a batch size of 128 and limit the maximum batch size to this value. If runtime is a big concern, manual increase of this parameter is possible. The version with batchsize 128 was already several times faster than Cell2Location.</p><p>DestVI with latent amortization showed superior performance in the setting with optimal mini-batch size in small datasets but performance was inferior for other mini-batch sizes. We continue suggesting both amortization and in the case of the brain dataset both amortization schemes were similar in performance.</p><p>Please share any feedback with us via twitter (@YosefLab), through the comment section below or through scverse discourse webpage (<a href="https://discourse.scverse.org/" target="_blank" rel="noopener noreferrer">https://discourse.scverse.org/</a>).</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="acknowledgements"></a>Acknowledgements<a class="hash-link" href="#acknowledgements" title="Direct link to heading">#</a></h2><p>We acknowledge members of the Yosef Lab. We thank Adam Gayoso for reviewing the changes to destVI and bringing the benchmarking study to our attention.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="bibliography"></a>Bibliography<a class="hash-link" href="#bibliography" title="Direct link to heading">#</a></h2><p>(1) Romain Lopez, Baoguo Li, Hadas Keren-Shaul, Pierre Boyeau, Merav Kedmi, David Pilzer, Adam Jelinski, Ido Yofe, Eyal David, Allon Wagner, Can Ergen, Yoseph Addadi, Ofra Golani, Franca Ronchese, Michael I. Jordan, Ido Amit and Nir Yosef. DestVI identifies continuums of cell types in spatial transcriptomics data. Nature Biotechnology. 2022.</p><p>(2) Vitalii Kleshchevnikov, Artem Shmatko, Emma Dann, Alexander Aivazidis, Hamish W. King, Tong Li, Rasa Elmentaite, Artem Lomakin, Veronika Kedlian, Adam Gayoso, Mika Sarkin Jain, Jun Sung Park, Lauma Ramona, Elizabeth Tuck, Anna Arutyunyan, Roser Vento-Tormo, Moritz Gerstung, Louisa James, Oliver Stegle and Omer Ali Bayraktar.  Cell2location maps fine-grained cell types in spatial transcriptomics. Nature Biotechnology. 2022.</p><p>(3) Bin Li, Wen Zhang, Chuang Guo, Hao Xu, Longfei Li, Minghao Fang, Yinlei Hu, Xinye Zhang, Xinfeng Yao, Meifang Tang, Ke Liu, Xuetong Zhao, Jun Lin, Linzhao Cheng, Falai Chen, Tian Xue and Kun Qu. Benchmarking spatial and single-cell transcriptomics integration methods for transcript distribution prediction and cell type deconvolution. Nature Methods. 2022.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/blog/tags/destvi">destvi</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/blog/tags/batch-size">batch-size</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/blog/v090">scvi-tools 0.9.0 release</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2021-03-03T00:00:00.000Z" itemprop="datePublished">March 3, 2021</time> ¬∑ 7 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a itemprop="url"><span itemprop="name">Adam Gayoso, Romain Lopez, Galen Xing, Nir Yosef</span></a></div></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Today we officially released <code>scvi-tools</code> version 0.9.0 (<a href="https://docs.scvi-tools.org/en/stable/release_notes/index.html" target="_blank" rel="noopener noreferrer">changelog</a>). This release marks the culmination of five months of work on the backend of the codebase, which came after three months of work on the frontend.
In this short note, we officially introduce <code>scvi-tools</code> as a readily usable codebase that contains many implementations of probabilistic single-cell omics methods, and also features a high-level interface to accelerate the model development process. We start with some historical notes about our previous codebase, which was mostly used for internal developments in the last three years. We then describe the obstacles we found to its external adoption, and the foundational idea behind the new <code>scvi-tools</code> work: a high-level deep probabilistic programming library specialized for single-cell omics data.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/blog/tags/scvi-tools">scvi-tools</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/blog/tags/release">release</a></li></ul></div><div class="col col--3 text--right"><a aria-label="Read more about scvi-tools 0.9.0 release" href="/blog/v090"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/blog/autotune">Hyperparameter search for scVI</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-07-05T00:00:00.000Z" itemprop="datePublished">July 5, 2019</time> ¬∑ 20 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a itemprop="url"><span itemprop="name">Gabriel Misrachi, Jeffrey Regier, Romain Lopez, Nir Yosef</span></a></div></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>While stochastic gradient-based optimization is highly successful for setting weights and other differentiable parameters of a neural network, it is in general useless for setting hyperparameters -- non-differentiable parameters that control the structure of the network (e.g. the number of hidden layers, or the dropout rate) or settings of the optimizer itself (e.g., the learning rate schedule). Yet finding good settings for hyperparameters is essential for good performance for deep methods like <a href="https://www.nature.com/articles/s41592-018-0229-2" target="_blank" rel="noopener noreferrer">scVI</a>. Furthermore, as pointed out by <a href="https://www.worldscientific.com/doi/pdf/10.1142/9789813279827_0033?download=true&amp;" target="_blank" rel="noopener noreferrer">Hu and Greene (2019)</a> selecting hyperparameters is nessary in order to compare different machine learning models, especially if those are substantially sensitive to hyperparameter variations.</p></div><footer class="row docusaurus-mt-lg"><div class="col col--3 text--right"><a aria-label="Read more about Hyperparameter search for scVI" href="/blog/autotune"><b>Read More</b></a></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="blogPostTitle_GeHD" itemprop="headline"><a itemprop="url" href="/blog/zero-inflation">Should we zero-inflate scVI?</a></h2><div class="blogPostData_291c margin-vert--md"><time datetime="2019-06-25T00:00:00.000Z" itemprop="datePublished">June 25, 2019</time> ¬∑ 22 min read</div><div class="row margin-top--md margin-bottom--sm"><div class="col col--6 authorCol_1R69"><div class="avatar margin-bottom--sm"><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a itemprop="url"><span itemprop="name">Oscar Clivio, Pierre Boyeau, Romain Lopez, Jeffrey Regier, Nir Yosef</span></a></div></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>Droplet- based single-cell RNA sequencing (scRNA-seq) datasets typically contain at least 90% zero entries. How can we best model these zeros? Recent work focused on modeling zeros with a mixture of count distributions. The first component is meant to reflect whether such an entry can be explained solely by the limited amount of sampling (on average ~5% or less of the molecules in the cell). The second component is generally used to reflect &quot;surprising&quot; zeros caused by measurement bias, transient transcriptional noise (e.g., &quot;bursty&quot; gene with a short mRNA half life), or true longer-term heterogeneity that can not be captured by a similified (low dimensional) representation of the data. Among others, zero-inflated distributions (i.e., zero-inflated negative binomial) have been widely adopted to model gene expression levels (1, 2).</p></div><footer class="row docusaurus-mt-lg"><div class="col col--9"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/blog/tags/autozi">autozi</a></li><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/blog/tags/zero-inflation">zero-inflation</a></li></ul></div><div class="col col--3 text--right"><a aria-label="Read more about Should we zero-inflate scVI?" href="/blog/zero-inflation"><b>Read More</b></a></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></main></div></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2025, Yosef Lab, Weizmann Institute of Science. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.1b571c78.js"></script>
<script src="/assets/js/main.19b51a5d.js"></script>
</body>
</html>